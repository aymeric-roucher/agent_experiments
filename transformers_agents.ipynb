{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q langchain numexpr sentencepiece plotly diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.chat_models import ChatHuggingFace, ChatOpenAI\n",
    "from langchain_core.tools import Tool\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "from scripts.modified_calculator import LLMMathChain\n",
    "from scripts.run_agents import answer_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_MODEL_ID = \"gpt-4-0125-preview\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.evaluation import load_benchmark\n",
    "import datasets\n",
    "\n",
    "eval_df = load_benchmark()\n",
    "eval_df[\"true_answer\"] = eval_df[\"true_answer\"].astype(str)\n",
    "eval_ds = datasets.Dataset.from_pandas(eval_df)\n",
    "\n",
    "OUTPUT_DIR = \"output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /Users/aymeric/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' To multiply 2 by the number 3.6452, you can simply multiply each digit of 2 by each digit of 3.6452 and sum up the results. However, since 2 is a single digit number, you can just multiply it by each digit of 3.6452 and sum up the results:\\n\\n2 \\\\* 3 = 6\\n2 \\\\* 6 = 12 (remember to carry the \"1\" to the next digit)\\n2 \\\\* 4 = 8 (add the carried \"1\" to this digit, making it 9)\\n2 \\\\* 5 = 10 (add the carried \"1\" to this digit, making it 11, but since we only have one digit after the decimal point, we need to round it to the nearest whole number, so the final result is 7.6452, but since we only want to keep 4 decimal places, we round it to 7.6452)\\n\\nTherefore, 2 \\\\* 3.6452 = 7.6452.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "from langchain.chat_models import ChatHuggingFace\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "    max_new_tokens=3000,\n",
    ")\n",
    "llm_engine = ChatHuggingFace(llm=llm)\n",
    "\n",
    "\n",
    "def call_llm(input: str, stop=[\"Observation\", \"Final Answer\"]) -> str:\n",
    "    return llm_engine.invoke(input, stop=stop).content\n",
    "\n",
    "\n",
    "call_llm(\"I should multiply 2 by 3.6452.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.tools.base import CalculatorTool, Tool\n",
    "\n",
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "\n",
    "params = {\n",
    "    \"engine\": \"bing\",\n",
    "    \"gl\": \"us\",\n",
    "    \"hl\": \"en\",\n",
    "}\n",
    "langchain_serpapi = SerpAPIWrapper(params=params)\n",
    "\n",
    "\n",
    "class SearchTool(Tool):\n",
    "    name = \"search\"\n",
    "    description = \"Search the web for information.\"\n",
    "\n",
    "    inputs = {\"query\": str}\n",
    "    outputs = [str]\n",
    "\n",
    "    def __call__(self, query: str) -> str:\n",
    "        return langchain_serpapi.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = SearchTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOOLBOX = [CalculatorTool(), SearchTool()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CodeAgent, ReactAgent\n",
    "\n",
    "# code_agent = CodeAgent(llm_callable=call_llm, toolbox=TOOLBOX)\n",
    "# react_agent = ReactAgent(llm_callable=call_llm, toolbox=TOOLBOX)\n",
    "\n",
    "# agents = {\n",
    "#     \"code\": code_agent,\n",
    "#     \"react\": react_agent,\n",
    "# }\n",
    "\n",
    "agents = {\n",
    "    \"vanilla_llm\": llm,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def call_transformers(agent, question: str) -> str:\n",
    "    result = agent.run(question)\n",
    "    return {\n",
    "        \"output\": str(result),\n",
    "        \"intermediate_steps\": agent.messages.copy(),\n",
    "    }\n",
    "\n",
    "\n",
    "async def call_llm(agent, question: str) -> str:\n",
    "    result = agent(question)\n",
    "    return {\n",
    "        \"output\": str(result),\n",
    "        \"intermediate_steps\": [],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': '\\nAnswer: 7.2904', 'intermediate_steps': []}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await call_llm(llm, \"I should multiply 2 by 3.6452.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [23:22<00:00, 15.58s/it] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent_name</th>\n",
       "      <th>question</th>\n",
       "      <th>prediction</th>\n",
       "      <th>intermediate_steps</th>\n",
       "      <th>parsing_error</th>\n",
       "      <th>iteration_limit_exceeded</th>\n",
       "      <th>agent_error</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>gt_answer</th>\n",
       "      <th>task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vanilla_llm</td>\n",
       "      <td>Mimi picked up 2 dozen seashells on the beach....</td>\n",
       "      <td>\\n\\nLet's reason through this problem:\\n\\n1. M...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-03-05 18:44:46</td>\n",
       "      <td>2024-03-05 18:44:51</td>\n",
       "      <td>16.0</td>\n",
       "      <td>gsm8k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vanilla_llm</td>\n",
       "      <td>Frankie's parents let him have many pets. He h...</td>\n",
       "      <td>\\n\\nFirst, we need to find out how many cats F...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-03-05 18:44:51</td>\n",
       "      <td>2024-03-05 18:45:12</td>\n",
       "      <td>19.0</td>\n",
       "      <td>gsm8k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vanilla_llm</td>\n",
       "      <td>Olaf collects colorful toy cars. At first, his...</td>\n",
       "      <td>\\n\\nLet's break this problem down:\\n1. First, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-03-05 18:45:12</td>\n",
       "      <td>2024-03-05 18:45:20</td>\n",
       "      <td>196.0</td>\n",
       "      <td>gsm8k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vanilla_llm</td>\n",
       "      <td>Emma's bank account has $100 in it. Each day o...</td>\n",
       "      <td>\\n\\nHere's how to tackle this problem:\\n\\n1. E...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-03-05 18:45:20</td>\n",
       "      <td>2024-03-05 18:45:25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>gsm8k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vanilla_llm</td>\n",
       "      <td>Ezekiel hikes as a hobby. This past summer, he...</td>\n",
       "      <td>\\n\\n### Watch This\\n\\nFirst watch this video.\\...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-03-05 18:45:25</td>\n",
       "      <td>2024-03-05 18:46:49</td>\n",
       "      <td>15.0</td>\n",
       "      <td>gsm8k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>vanilla_llm</td>\n",
       "      <td>How many at bats did the Yankee with the most ...</td>\n",
       "      <td>\\n\\nReggie Jackson had the most walks in the 1...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-03-05 19:05:54</td>\n",
       "      <td>2024-03-05 19:06:01</td>\n",
       "      <td>519</td>\n",
       "      <td>GAIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>vanilla_llm</td>\n",
       "      <td>In Audre Lorde’s poem “Father Son and Holy Gho...</td>\n",
       "      <td>\\n\\n1. Second\\n2. Third\\n3. Fourth\\n4. Fifth\\n...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-03-05 19:06:01</td>\n",
       "      <td>2024-03-05 19:06:03</td>\n",
       "      <td>2</td>\n",
       "      <td>GAIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>vanilla_llm</td>\n",
       "      <td>Where were the Vietnamese specimens described ...</td>\n",
       "      <td>\\n\\nTonkin (northern Vietnam)\\n\\nHaiphong\\n\\n-...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-03-05 19:06:03</td>\n",
       "      <td>2024-03-05 19:07:37</td>\n",
       "      <td>Saint Petersburg</td>\n",
       "      <td>GAIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>vanilla_llm</td>\n",
       "      <td>What country had the least number of athletes ...</td>\n",
       "      <td>\\n\\nAnswer: MON (Monaco)\\n\\nMonaco is a small ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-03-05 19:07:37</td>\n",
       "      <td>2024-03-05 19:07:44</td>\n",
       "      <td>CUB</td>\n",
       "      <td>GAIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>vanilla_llm</td>\n",
       "      <td>What is the first name of the only Malko Compe...</td>\n",
       "      <td>\\n\\nGregor Huebner (b. 1972) is the first and ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-03-05 19:07:44</td>\n",
       "      <td>2024-03-05 19:08:08</td>\n",
       "      <td>Claus</td>\n",
       "      <td>GAIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     agent_name                                           question  \\\n",
       "0   vanilla_llm  Mimi picked up 2 dozen seashells on the beach....   \n",
       "1   vanilla_llm  Frankie's parents let him have many pets. He h...   \n",
       "2   vanilla_llm  Olaf collects colorful toy cars. At first, his...   \n",
       "3   vanilla_llm  Emma's bank account has $100 in it. Each day o...   \n",
       "4   vanilla_llm  Ezekiel hikes as a hobby. This past summer, he...   \n",
       "..          ...                                                ...   \n",
       "85  vanilla_llm  How many at bats did the Yankee with the most ...   \n",
       "86  vanilla_llm  In Audre Lorde’s poem “Father Son and Holy Gho...   \n",
       "87  vanilla_llm  Where were the Vietnamese specimens described ...   \n",
       "88  vanilla_llm  What country had the least number of athletes ...   \n",
       "89  vanilla_llm  What is the first name of the only Malko Compe...   \n",
       "\n",
       "                                           prediction intermediate_steps  \\\n",
       "0   \\n\\nLet's reason through this problem:\\n\\n1. M...                 []   \n",
       "1   \\n\\nFirst, we need to find out how many cats F...                 []   \n",
       "2   \\n\\nLet's break this problem down:\\n1. First, ...                 []   \n",
       "3   \\n\\nHere's how to tackle this problem:\\n\\n1. E...                 []   \n",
       "4   \\n\\n### Watch This\\n\\nFirst watch this video.\\...                 []   \n",
       "..                                                ...                ...   \n",
       "85  \\n\\nReggie Jackson had the most walks in the 1...                 []   \n",
       "86  \\n\\n1. Second\\n2. Third\\n3. Fourth\\n4. Fifth\\n...                 []   \n",
       "87  \\n\\nTonkin (northern Vietnam)\\n\\nHaiphong\\n\\n-...                 []   \n",
       "88  \\n\\nAnswer: MON (Monaco)\\n\\nMonaco is a small ...                 []   \n",
       "89  \\n\\nGregor Huebner (b. 1972) is the first and ...                 []   \n",
       "\n",
       "    parsing_error  iteration_limit_exceeded agent_error           start_time  \\\n",
       "0           False                     False        None  2024-03-05 18:44:46   \n",
       "1           False                     False        None  2024-03-05 18:44:51   \n",
       "2           False                     False        None  2024-03-05 18:45:12   \n",
       "3           False                     False        None  2024-03-05 18:45:20   \n",
       "4           False                     False        None  2024-03-05 18:45:25   \n",
       "..            ...                       ...         ...                  ...   \n",
       "85          False                     False        None  2024-03-05 19:05:54   \n",
       "86          False                     False        None  2024-03-05 19:06:01   \n",
       "87          False                     False        None  2024-03-05 19:06:03   \n",
       "88          False                     False        None  2024-03-05 19:07:37   \n",
       "89          False                     False        None  2024-03-05 19:07:44   \n",
       "\n",
       "               end_time         gt_answer   task  \n",
       "0   2024-03-05 18:44:51              16.0  gsm8k  \n",
       "1   2024-03-05 18:45:12              19.0  gsm8k  \n",
       "2   2024-03-05 18:45:20             196.0  gsm8k  \n",
       "3   2024-03-05 18:45:25               4.0  gsm8k  \n",
       "4   2024-03-05 18:46:49              15.0  gsm8k  \n",
       "..                  ...               ...    ...  \n",
       "85  2024-03-05 19:06:01               519   GAIA  \n",
       "86  2024-03-05 19:06:03                 2   GAIA  \n",
       "87  2024-03-05 19:07:37  Saint Petersburg   GAIA  \n",
       "88  2024-03-05 19:07:44               CUB   GAIA  \n",
       "89  2024-03-05 19:08:08             Claus   GAIA  \n",
       "\n",
       "[90 rows x 11 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.run_agents import run_full_tests\n",
    "\n",
    "await run_full_tests(\n",
    "    eval_ds,\n",
    "    agents,\n",
    "    output_folder=OUTPUT_DIR,\n",
    "    agent_call_function=call_llm,\n",
    "    key_for_answer=\"true_answer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "answer_file_path = f\"{OUTPUT_DIR}/answers.jsonl\"\n",
    "\n",
    "result_df = pd.concat([pd.read_json(f) for f in glob.glob(f\"{OUTPUT_DIR}/*.json\")])\n",
    "result_df = result_df.drop(columns=[\"start_time\", \"end_time\"])\n",
    "result_df.to_json(answer_file_path, lines=True, orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exact match for GSM8K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error when extracting string: could not convert string to float: '2U'\n",
      "Error when extracting string: could not convert string to float: '4x'\n",
      "Error when extracting string: could not convert string to float: '3r'\n"
     ]
    }
   ],
   "source": [
    "from scripts.evaluation import score_any_match\n",
    "\n",
    "results_math = result_df.loc[result_df[\"task\"] == \"gsm8k\"].copy()\n",
    "results_math[\"exact_match\"] = -1\n",
    "results_math[\"exact_match\"] = results_math.apply(\n",
    "    lambda row: score_any_match(row[\"prediction\"], float(row[\"gt_answer\"])), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agent_name\n",
       "vanilla_llm    40\n",
       "code           40\n",
       "react          40\n",
       "react_prev     40\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_math[\"agent_name\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agent_name   task \n",
       "code         gsm8k    0.675\n",
       "react        gsm8k    0.375\n",
       "react_prev   gsm8k    0.425\n",
       "vanilla_llm  gsm8k    0.650\n",
       "Name: exact_match, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_math.groupby([\"agent_name\", \"task\"])[\"exact_match\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM as a judge for others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = result_df.loc[result_df[\"task\"] != \"gsm8k\"].to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "eval_chat_model = ChatOpenAI(model=\"gpt-4-1106-preview\", temperature=0)\n",
    "eval_model_name = \"GPT4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous evaluations:\n",
      "Launching evaluation for 50 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n",
      "Evaluating example\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:26<00:00,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation is complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from scripts.evaluation import evaluate_answers\n",
    "from scripts.prompts import EVALUATION_PROMPT_TEMPLATE\n",
    "\n",
    "output_file_path = f\"{OUTPUT_DIR}/evaluation.jsonl\"\n",
    "\n",
    "run_evaluation = True\n",
    "if run_evaluation:\n",
    "    results = await evaluate_answers(\n",
    "        answers,\n",
    "        eval_chat_model,\n",
    "        \"GPT4\",\n",
    "        EVALUATION_PROMPT_TEMPLATE,\n",
    "        output_file_path=output_file_path,\n",
    "    )\n",
    "\n",
    "    print(\"Evaluation is complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agent_name\n",
       "code           0.255\n",
       "react          0.345\n",
       "react_prev     0.335\n",
       "vanilla_llm    0.440\n",
       "Name: eval_score_GPT4, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_nonmath = pd.DataFrame.from_dict(results)\n",
    "\n",
    "\n",
    "def interpret_score(eval_score):\n",
    "    try:\n",
    "        return (float(eval_score) - 1) / 4\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "\n",
    "results_nonmath[\"eval_score_GPT4\"] = results_nonmath[\"eval_score_GPT4\"].apply(\n",
    "    interpret_score\n",
    ")\n",
    "results_nonmath.groupby(\"agent_name\")[\"eval_score_GPT4\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agent_name   task    \n",
       "code         GAIA             12.5\n",
       "             HotpotQA    34.166667\n",
       "             gsm8k            67.5\n",
       "react        GAIA            13.75\n",
       "             HotpotQA    48.333333\n",
       "             gsm8k            37.5\n",
       "react_prev   GAIA             8.75\n",
       "             HotpotQA         50.0\n",
       "             gsm8k            42.5\n",
       "vanilla_llm  GAIA            26.25\n",
       "             HotpotQA    55.833333\n",
       "             gsm8k            65.0\n",
       "Name: aggregate_score, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.concat([results_math, results_nonmath])\n",
    "result_df[\"aggregate_score\"] = (\n",
    "    result_df[\"exact_match\"].fillna(0) + result_df[\"eval_score_GPT4\"].fillna(0)\n",
    ") * 100\n",
    "result_df.groupby([\"agent_name\", \"task\"])[\"aggregate_score\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aymeric/venvs/ml/lib/python3.11/site-packages/plotly/express/_core.py:2065: FutureWarning:\n",
      "\n",
      "When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "<b>Task</b>=GAIA<br><b>Agent</b>=%{x}<br>Performance=%{y}<extra></extra>",
         "legendgroup": "GAIA",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "GAIA",
         "offsetgroup": "GAIA",
         "orientation": "v",
         "showlegend": true,
         "textposition": "outside",
         "texttemplate": "%{y:.0f}",
         "type": "bar",
         "x": [
          "CodeAgent",
          "ReactAgent",
          "ReactAgent (previous)",
          "LLM"
         ],
         "xaxis": "x",
         "y": [
          12.5,
          13.75,
          8.75,
          26.25
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "<b>Task</b>=HotpotQA<br><b>Agent</b>=%{x}<br>Performance=%{y}<extra></extra>",
         "legendgroup": "HotpotQA",
         "marker": {
          "color": "#EF553B",
          "pattern": {
           "shape": ""
          }
         },
         "name": "HotpotQA",
         "offsetgroup": "HotpotQA",
         "orientation": "v",
         "showlegend": true,
         "textposition": "outside",
         "texttemplate": "%{y:.0f}",
         "type": "bar",
         "x": [
          "CodeAgent",
          "ReactAgent",
          "ReactAgent (previous)",
          "LLM"
         ],
         "xaxis": "x",
         "y": [
          34.166666666666664,
          48.333333333333336,
          50,
          55.833333333333336
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "<b>Task</b>=gsm8k<br><b>Agent</b>=%{x}<br>Performance=%{y}<extra></extra>",
         "legendgroup": "gsm8k",
         "marker": {
          "color": "#00cc96",
          "pattern": {
           "shape": ""
          }
         },
         "name": "gsm8k",
         "offsetgroup": "gsm8k",
         "orientation": "v",
         "showlegend": true,
         "textposition": "outside",
         "texttemplate": "%{y:.0f}",
         "type": "bar",
         "x": [
          "CodeAgent",
          "ReactAgent",
          "ReactAgent (previous)",
          "LLM"
         ],
         "xaxis": "x",
         "y": [
          67.5,
          37.5,
          42.5,
          65
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "bargap": 0.35,
        "bargroupgap": 0,
        "barmode": "group",
        "height": 600,
        "legend": {
         "title": {
          "text": "<b>Task</b>"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "width": 1000,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "<b>Agent</b>"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "range": [
          0,
          100
         ],
         "ticksuffix": "%",
         "title": {
          "text": "Performance"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "aggregate = (\n",
    "    result_df.groupby([\"agent_name\", \"task\"])[[\"aggregate_score\"]].mean().reset_index()\n",
    ")\n",
    "aggregate[\"agent_name\"] = aggregate[\"agent_name\"].map(\n",
    "    {\n",
    "        \"vanilla_llm\": \"LLM\",\n",
    "        \"react\": \"ReactAgent\",\n",
    "        \"code\": \"CodeAgent\",\n",
    "        \"react_prev\": \"ReactAgent (previous)\",\n",
    "    }\n",
    ")\n",
    "fig = px.bar(\n",
    "    aggregate,\n",
    "    x=\"agent_name\",\n",
    "    y=\"aggregate_score\",\n",
    "    color=\"task\",\n",
    "    labels={\n",
    "        \"agent_name\": \"<b>Agent</b>\",\n",
    "        \"task\": \"<b>Task</b>\",\n",
    "        \"aggregate_score\": \"Performance\",\n",
    "        \"eval_score_GPT4\": \"<b>Score</b>\",\n",
    "    },\n",
    ")\n",
    "fig.update_layout(\n",
    "    width=len(aggregate[\"agent_name\"].unique()) * 200 + 200,\n",
    "    height=600,\n",
    "    barmode=\"group\",\n",
    "    bargap=0.35,\n",
    "    bargroupgap=0.0,\n",
    "    yaxis_range=[0, 100],\n",
    ")\n",
    "fig.update_traces(texttemplate=\"%{y:.0f}\", textposition=\"outside\")\n",
    "fig.layout.yaxis.ticksuffix = \"%\"\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
